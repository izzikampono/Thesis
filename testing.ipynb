{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from decpomdp import DecPOMDP\n",
    "import time\n",
    "import random\n",
    "import os\n",
    "from constant import Constants\n",
    "import gc \n",
    "gc.enable()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game size :\n",
      "\t|S| = 4\n",
      "\t|Z| = 9\n",
      "\t|U| = 9 with |U_i| = 3\n",
      "intiial_belief : [['shuffle', 'exchange', 'sense'], ['shuffle', 'exchange', 'sense']]\n"
     ]
    }
   ],
   "source": [
    "#set problem \n",
    "file_name = \"relay4\"\n",
    "planning_horizon = 3\n",
    "num_iterations = 3\n",
    "sota_ = False\n",
    "game_type = \"zerosum\"\n",
    "\n",
    "\n",
    "problem = DecPOMDP(file_name,horizon=planning_horizon)\n",
    "Constants.initialize(problem)\n",
    "constant = Constants.get_instance()\n",
    "from pbvi import PBVI\n",
    "from experimentFunctions import Experiment\n",
    "experiment = Experiment(planning_horizon,problem)\n",
    "print(f\"game size :\\n\\t|S| = {len(problem.states)}\")\n",
    "print(f\"\\t|Z| = {problem.num_joint_observations}\\n\\t|U| = {problem.num_joint_actions} with |U_i| = {problem.num_actions[0]}\")\n",
    "print(f\"intiial_belief : {problem.actions}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "REWARD MATRIX OF zerosum relay4 GAME\n",
      "\n",
      "Leader :\n",
      "   l1_r1  l1_r2  l2_r1  l2_r2\n",
      "0   -1.0   -1.0   -1.0   -1.0\n",
      "1  -50.0  -50.0  -50.0  -50.0\n",
      "2   -1.0   -1.0   -1.0   -1.0\n",
      "3  -50.0  -50.0  -50.0  -50.0\n",
      "4   50.0  -50.0  -50.0  -50.0\n",
      "5  -50.0  -50.0  -50.0  -50.0\n",
      "6   -1.0   -1.0   -1.0   -1.0\n",
      "7  -50.0  -50.0  -50.0  -50.0\n",
      "8   -1.0   -1.0   -1.0   -1.0\n",
      "\n",
      "Follower :\n",
      "   l1_r1  l1_r2  l2_r1  l2_r2\n",
      "0    1.0    1.0    1.0    1.0\n",
      "1   50.0   50.0   50.0   50.0\n",
      "2    1.0    1.0    1.0    1.0\n",
      "3   50.0   50.0   50.0   50.0\n",
      "4  -50.0   50.0   50.0   50.0\n",
      "5   50.0   50.0   50.0   50.0\n",
      "6    1.0    1.0    1.0    1.0\n",
      "7   50.0   50.0   50.0   50.0\n",
      "8    1.0    1.0    1.0    1.0\n"
     ]
    }
   ],
   "source": [
    "#see reward matrix of both player\n",
    "print(f\"REWARD MATRIX OF {game_type} {problem.name} GAME\")\n",
    "print(\"\\nLeader :\")\n",
    "print(f\"{pd.DataFrame(constant.REWARDS[game_type][0],columns=problem.states)}\")\n",
    "print(\"\\nFollower :\")\n",
    "print(f\"{pd.DataFrame(constant.REWARDS[game_type][1],columns=problem.states)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t Solving zerosum relay4 GAME WITH SOTA False 3 \n",
      "\tbelief expansion done, belief space size = 60\n",
      "\n",
      "iteration : 1\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13429f8e0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134549b40>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134593d60>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1345edff0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x1345c2fb0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.45 0.05 0.45]  -- DR <decisionRule.DecisionRule object at 0x134548790>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x13454e650>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x134605e70>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.05 0.45 0.45]  -- DR <decisionRule.DecisionRule object at 0x1345904c0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x1345a99c0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x1345e4e80>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x1345ab7c0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x134627e20>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x1345910c0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x1346054e0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x13454f4f0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x134578190>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13465a380>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-41.77852348993288, 41.77852348993289), tabular LP value : (-41.77852348993288, 41.77852348993289)  --  Reconstructed Max plane alpha: (-41.77852348993289, 41.77852348993289), reconstructed tabular alpha : (-41.77852348993289, 41.77852348993289)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1345c1270>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x13454bd30>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13454d120>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.85878962536023, 50.85878962536023), tabular LP value : (-50.85878962536023, 50.85878962536023)  --  Reconstructed Max plane alpha: (-50.85878962536023, 50.85878962536023), reconstructed tabular alpha : (-50.85878962536023, 50.85878962536023)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134596320>\n",
      "\n",
      "iteration : 2\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1346c8cd0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13451beb0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134625c30>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13470c700>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x134604af0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.45 0.05 0.45]  -- DR <decisionRule.DecisionRule object at 0x1342d11b0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x134745f00>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x134627820>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.05 0.45 0.45]  -- DR <decisionRule.DecisionRule object at 0x1346cbf70>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x13451b3d0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x13475ffd0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x1345ed8a0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x13457ae00>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x13479c790>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x134548730>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x1345eddb0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x134604550>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13454ddb0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-41.77852348993288, 41.77852348993289), tabular LP value : (-41.77852348993288, 41.77852348993289)  --  Reconstructed Max plane alpha: (-41.77852348993289, 41.77852348993289), reconstructed tabular alpha : (-41.77852348993289, 41.77852348993289)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1345e4760>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1345aa9b0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1347ee4d0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.85878962536023, 50.85878962536023), tabular LP value : (-50.85878962536023, 50.85878962536023)  --  Reconstructed Max plane alpha: (-50.85878962536023, 50.85878962536023), reconstructed tabular alpha : (-50.85878962536023, 50.85878962536023)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134518190>\n",
      "\n",
      "iteration : 3\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134744b80>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1345e54b0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134578d00>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134593190>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x13454e5f0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.45 0.05 0.45]  -- DR <decisionRule.DecisionRule object at 0x134855b10>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x13454abc0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x1347beef0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.05 0.45 0.45]  -- DR <decisionRule.DecisionRule object at 0x13454dab0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x13488cdf0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x1348222c0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x134770880>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x13478bee0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x13470dcc0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x13468cb50>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x13454f7f0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x1348b8700>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134591150>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-41.77852348993288, 41.77852348993289), tabular LP value : (-41.77852348993288, 41.77852348993289)  --  Reconstructed Max plane alpha: (-41.77852348993289, 41.77852348993289), reconstructed tabular alpha : (-41.77852348993289, 41.77852348993289)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1345a8250>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1348cc7c0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1348d4dc0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.85878962536023, 50.85878962536023), tabular LP value : (-50.85878962536023, 50.85878962536023)  --  Reconstructed Max plane alpha: (-50.85878962536023, 50.85878962536023), reconstructed tabular alpha : (-50.85878962536023, 50.85878962536023)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1345a9150>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "================================================= END OF zerosum GAME WITH SOTA False ======================================================================\n",
      "\n",
      "\t\t\tpoint value at initial belief  (-50.85878962536023, 50.85878962536023)\n",
      "\t\t\talphavectors value at inital belief (V0,V1) : (-50.85878962536023, 50.85878962536023)\n",
      "\n",
      "\n",
      "==========================================================================================================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(-50.85878962536023, 50.85878962536023),\n",
       " (-50.85878962536023, 50.85878962536023),\n",
       " (-50.85878962536023, 50.85878962536023)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values,times ,tabular_value= experiment.run_single_experiment(density=0.00001,gametype=game_type,limit=1000,sota=False,iterations=num_iterations)\n",
    "values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\t Solving cooperative relay4 GAME WITH SOTA False 1 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134590070>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1346cb190>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134857280>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (0.0, 0.0)\n",
      "alphavectors value at inital belief (V0,V1) : (0.0, 0.0)\n",
      "\n",
      "\n",
      "\t\t\t Solving cooperative relay4 GAME WITH SOTA False 2 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 9\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13454e560>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1345aa440>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1348d73a0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134788490>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1340b47c0>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 15\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1347bc5e0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134518e50>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x107fd8220>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134773250>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1345975b0>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 17\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13475e380>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1340b4b80>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134076ec0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13451b7c0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1348bbca0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (-1.0, -1.0)\n",
      "alphavectors value at inital belief (V0,V1) : (-1.0, -1.0)\n",
      "\n",
      "\n",
      "\t\t\t Solving cooperative relay4 GAME WITH SOTA False 3 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 11\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1347d58d0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13421aa10>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1347bf9a0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134626020>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x1347d7190>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x1348bbcd0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x13492ba60>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x134773fa0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x1347bc910>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1347bead0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134597040>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134789870>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134823f70>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1348d5810>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 21\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1348bb6a0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134820610>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1347d6cb0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134624ee0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x134596830>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x134857790>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x1348bb730>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x13429c0d0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x134770fd0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x134578f10>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x1348ce590>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x13429e770>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x1345ecdf0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x1348d5ff0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x1348cd3f0>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1340b4880>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1346cafe0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1348225c0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1345793c0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134740d90>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 60\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134604f10>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1340b47f0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1348cc790>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13429dd20>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x1347d43a0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.45 0.05 0.45]  -- DR <decisionRule.DecisionRule object at 0x1348cf4c0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x134610e50>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x134624e50>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.05 0.45 0.45]  -- DR <decisionRule.DecisionRule object at 0x1347d5960>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x1348b8b80>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x13475f100>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x134604bb0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x134592d40>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x13461f7f0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x1346269b0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x1347d5150>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x13429c5e0>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134959450>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1340777c0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x13461f670>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1346c8ac0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134595f60>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (-1.0, -1.0)\n",
      "alphavectors value at inital belief (V0,V1) : (-1.0, -1.0)\n",
      "\n",
      "\n",
      "\t\t\t Solving cooperative relay4 GAME WITH SOTA True 1 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1346266e0>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1347bfe50>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134591d80>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (0.0, 0.0)\n",
      "alphavectors value at inital belief (V0,V1) : (0.0, 0.0)\n",
      "\n",
      "\n",
      "\t\t\t Solving cooperative relay4 GAME WITH SOTA True 2 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 9\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13475cb20>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13475ee60>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1346c9f90>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1346c8ac0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134740d90>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 15\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134595f60>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13475d630>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x13464b3d0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1346ca440>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1346ca4d0>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 17\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13429d270>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13429c790>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x13429c820>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1345974f0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13475dc60>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (-1.0, -1.0)\n",
      "alphavectors value at inital belief (V0,V1) : (-1.0, -1.0)\n",
      "\n",
      "\n",
      "\t\t\t Solving cooperative relay4 GAME WITH SOTA True 3 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 11\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13475d630>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13475f2e0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x13429ebf0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13429c5e0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x13429d870>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x13429ea70>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x13429cc40>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x13429e770>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x13429d780>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1349299c0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13492bca0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x13492b070>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13492a200>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134928910>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 21\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1349292a0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1346700a0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1348d7f40>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13429d6f0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x13429cd00>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x13429d690>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x13429d840>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x13429c790>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x13429dcf0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x13429c0d0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x1348cf220>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x1348cc6d0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x1348cfa30>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x1348ccdf0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x1348cee60>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134741f60>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13492a500>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134928730>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13492b160>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13492b2b0>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 60\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1348cfa00>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1348cc0a0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134928f40>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13475c160>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x13492b7c0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.45 0.05 0.45]  -- DR <decisionRule.DecisionRule object at 0x13429c8b0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x13475f100>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x13429f550>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.05 0.45 0.45]  -- DR <decisionRule.DecisionRule object at 0x134627700>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x13429c250>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x13429cf70>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x1348cd5d0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x1348ccb80>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x1348cd3f0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x1348cccd0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x1348cfeb0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x13461fd30>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13461f8e0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1348cfa90>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1345916c0>\n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134594220>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game cooperative  ::  max plane LP value: (-1.0, -1.0), tabular LP value : (-1.0, -1.0)  --  Reconstructed Max plane alpha: (-1.0, -1.0), reconstructed tabular alpha : (-1.0, -1.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134596bf0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (-1.0, -1.0)\n",
      "alphavectors value at inital belief (V0,V1) : (-1.0, -1.0)\n",
      "\n",
      "\n",
      "\t\t\t Solving zerosum relay4 GAME WITH SOTA False 1 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1346045b0>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1348b8130>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134076b30>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (0.0, 0.0)\n",
      "alphavectors value at inital belief (V0,V1) : (0.0, 0.0)\n",
      "\n",
      "\n",
      "\t\t\t Solving zerosum relay4 GAME WITH SOTA False 2 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 9\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13421b820>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1348b9000>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1349a1360>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1346cb6a0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13457bd90>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 15\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1347d5a50>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134077b80>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134625960>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134595240>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1348ba3e0>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 17\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1347d41f0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13492bca0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134627550>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134a3a5c0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134620730>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (-50.0, 50.0)\n",
      "alphavectors value at inital belief (V0,V1) : (-50.0, 50.0)\n",
      "\n",
      "\n",
      "\t\t\t Solving zerosum relay4 GAME WITH SOTA False 3 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 11\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134610850>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1347d6f20>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134741480>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134772bc0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x1348bb250>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x134a61750>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x134788e20>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x1349a00d0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x134a7dcf0>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134607a00>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-41.77852348993288, 41.77852348993289), tabular LP value : (-41.77852348993288, 41.77852348993289)  --  Reconstructed Max plane alpha: (-41.77852348993289, 41.77852348993289), reconstructed tabular alpha : (-41.77852348993289, 41.77852348993289)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1348cf700>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1348b83d0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134a34250>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.85878962536023, 50.85878962536023), tabular LP value : (-50.85878962536023, 50.85878962536023)  --  Reconstructed Max plane alpha: (-50.85878962536023, 50.85878962536023), reconstructed tabular alpha : (-50.85878962536023, 50.85878962536023)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134821e40>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 21\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1346270a0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134aecdc0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134a84460>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134627880>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x134aed0c0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x134b1f280>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x1348bbd00>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x1347d46a0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x134ab0e80>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x134a7d000>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x134596c80>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x1348b8dc0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x134b75d50>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x134a06680>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x13454b820>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13470f5b0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-41.77852348993288, 41.77852348993289), tabular LP value : (-41.77852348993288, 41.77852348993289)  --  Reconstructed Max plane alpha: (-41.77852348993289, 41.77852348993289), reconstructed tabular alpha : (-41.77852348993289, 41.77852348993289)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1345c3730>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134857250>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13468f3a0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.85878962536023, 50.85878962536023), tabular LP value : (-50.85878962536023, 50.85878962536023)  --  Reconstructed Max plane alpha: (-50.85878962536023, 50.85878962536023), reconstructed tabular alpha : (-50.85878962536023, 50.85878962536023)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1349701c0>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 60\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1348cfca0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1347d42e0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1349d9fc0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134a94250>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x13470f8e0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.45 0.05 0.45]  -- DR <decisionRule.DecisionRule object at 0x1345482e0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x1347d5300>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x134a63f10>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.05 0.45 0.45]  -- DR <decisionRule.DecisionRule object at 0x134973430>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x13468d570>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x1345a8610>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x134733220>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x1339ab880>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x1349703d0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x134a62890>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x13454a470>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x1349db820>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134a85bd0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-41.77852348993288, 41.77852348993289), tabular LP value : (-41.77852348993288, 41.77852348993289)  --  Reconstructed Max plane alpha: (-41.77852348993289, 41.77852348993289), reconstructed tabular alpha : (-41.77852348993289, 41.77852348993289)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1348f4d30>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134b024a0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, 50.0), tabular LP value : (-50.0, 50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134745780>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.85878962536023, 50.85878962536023), tabular LP value : (-50.85878962536023, 50.85878962536023)  --  Reconstructed Max plane alpha: (-50.85878962536023, 50.85878962536023), reconstructed tabular alpha : (-50.85878962536023, 50.85878962536023)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134789390>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (-50.85878962536023, 50.85878962536023)\n",
      "alphavectors value at inital belief (V0,V1) : (-50.85878962536023, 50.85878962536023)\n",
      "\n",
      "\n",
      "\t\t\t Solving zerosum relay4 GAME WITH SOTA True 1 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13468f520>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134732350>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13475e620>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (0.0, 0.0)\n",
      "alphavectors value at inital belief (V0,V1) : (0.0, 0.0)\n",
      "\n",
      "\n",
      "\t\t\t Solving zerosum relay4 GAME WITH SOTA True 2 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 9\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13454b430>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134972680>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x13470dd80>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13468c280>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.0, -50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1348f7ca0>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 15\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1348d5930>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1349dba90>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134a84cd0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13429f5b0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.0, -50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134746350>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 17\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13468ead0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13429d810>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1347465c0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1346275b0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.0, -50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1347d6920>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (-50.0, 50.0)\n",
      "alphavectors value at inital belief (V0,V1) : (-50.0, 50.0)\n",
      "\n",
      "\n",
      "\t\t\t Solving zerosum relay4 GAME WITH SOTA True 3 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 11\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1345aac80>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13468e830>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134972a10>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1349704c0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x134855ff0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x1348f6200>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x134a94550>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x13454b880>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x1346fc250>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.0, -50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134971180>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-41.77852348993289, -41.77852348993289), tabular LP value : (-41.77852348993289, -41.77852348993289)  --  Reconstructed Max plane alpha: (-41.77852348993289, 41.77852348993289), reconstructed tabular alpha : (-41.77852348993289, 41.77852348993289)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134855ab0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.0, -50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134a87040>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.0, -50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13454a5f0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.85878962536023, -50.85878962536023)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.85878962536023, 50.85878962536023)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1345abca0>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 21\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134972c50>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1348f6800>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1348d7cd0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134549960>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x134744be0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x1345aaa40>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x1346204f0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x13468e560>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x134af91b0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x134622b90>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x134a4ea40>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x134856380>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x134b8ad10>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x1346264a0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x134747cd0>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.0, -50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134a84e50>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-41.77852348993289, -41.77852348993289), tabular LP value : (-41.77852348993289, -41.77852348993289)  --  Reconstructed Max plane alpha: (-41.77852348993289, 41.77852348993289), reconstructed tabular alpha : (-41.77852348993289, 41.77852348993289)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134623400>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.0, -50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x13421a0e0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.0, -50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134b622c0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.85878962536023, -50.85878962536023)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.85878962536023, 50.85878962536023)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134bba470>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 60\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134928670>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13468e8f0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134973d00>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134855720>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x1346230d0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.45 0.05 0.45]  -- DR <decisionRule.DecisionRule object at 0x134be1060>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x1349ee2c0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x133c275b0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.05 0.45 0.45]  -- DR <decisionRule.DecisionRule object at 0x134be2ef0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x134ad0610>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x134bc7e80>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x13468f1f0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x13470f3d0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x134b9efe0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x134854c70>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x13470d630>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x134771270>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.0, -50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1346588b0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-41.77852348993289, -41.77852348993289), tabular LP value : (-41.77852348993289, -41.77852348993289)  --  Reconstructed Max plane alpha: (-41.77852348993289, 41.77852348993289), reconstructed tabular alpha : (-41.77852348993289, 41.77852348993289)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1349db7c0>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.0, -50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1346c9270>\n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.0, -50.0)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.0, 50.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134a7e8f0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game zerosum  ::  max plane LP value: (-50.0, -50.0), tabular LP value : (-50.85878962536023, -50.85878962536023)  --  Reconstructed Max plane alpha: (-50.0, 50.0), reconstructed tabular alpha : (-50.85878962536023, 50.85878962536023)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134578340>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (-50.85878962536023, 50.85878962536023)\n",
      "alphavectors value at inital belief (V0,V1) : (-50.0, 50.0)\n",
      "\n",
      "\n",
      "\t\t\t Solving stackelberg relay4 GAME WITH SOTA False 1 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1346cbd30>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134077a30>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1348ccd30>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (0.0, 0.0)\n",
      "alphavectors value at inital belief (V0,V1) : (0.0, 0.0)\n",
      "\n",
      "\n",
      "\t\t\t Solving stackelberg relay4 GAME WITH SOTA False 2 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 9\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13488ecb0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1345e7040>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1347735b0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134885540>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 35.75), tabular LP value : (-1.0, 35.75)  --  Reconstructed Max plane alpha: (-1.0, 35.75), reconstructed tabular alpha : (-1.0, 35.75)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134bc4730>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 15\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1346ca4d0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x107f60880>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1348cdd50>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1349db8e0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 35.75), tabular LP value : (-1.0, 35.75)  --  Reconstructed Max plane alpha: (-1.0, 35.75), reconstructed tabular alpha : (-1.0, 35.75)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1347718d0>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 17\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1345ec220>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13457a800>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1346fe860>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1348879a0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 35.75), tabular LP value : (-1.0, 35.75)  --  Reconstructed Max plane alpha: (-1.0, 35.75), reconstructed tabular alpha : (-1.0, 35.75)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1345e73a0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (-1.0, 35.75)\n",
      "alphavectors value at inital belief (V0,V1) : (-1.0, 35.75)\n",
      "\n",
      "\n",
      "\t\t\t Solving stackelberg relay4 GAME WITH SOTA False 3 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 11\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1345efdf0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134bc4760>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x13470f2b0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1348cc1c0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x1348b95d0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x1346fe770>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x13457ae00>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x13470ce20>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x13454b070>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 35.75), tabular LP value : (-1.0, 35.75)  --  Reconstructed Max plane alpha: (-1.0, 35.75), reconstructed tabular alpha : (-1.0, 35.75)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134ab36d0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.4267053701015966, 21.167634252539912), tabular LP value : (-1.4267053701015966, 21.167634252539912)  --  Reconstructed Max plane alpha: (-1.4267053701015968, 21.167634252539912), reconstructed tabular alpha : (-1.4267053701015968, 21.167634252539912)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13457a920>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 22.625), tabular LP value : (-1.0, 22.625)  --  Reconstructed Max plane alpha: (-1.0, 22.625), reconstructed tabular alpha : (-1.0, 22.625)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134a37d00>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 27.375), tabular LP value : (-1.0, 27.375)  --  Reconstructed Max plane alpha: (-1.0, 27.375), reconstructed tabular alpha : (-1.0, 27.375)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1345ef2b0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.9869683008338468, 65.1051780847474), tabular LP value : (-1.9869683008338468, 65.1051780847474)  --  Reconstructed Max plane alpha: (-1.9869683008338468, 65.1051780847474), reconstructed tabular alpha : (-1.9869683008338468, 65.1051780847474)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134ab19f0>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 21\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13488e680>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134549db0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1345e4d00>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134625120>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x134820a60>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x134a7e170>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x1349d82b0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x1348cd9f0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x1349e0e20>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x1345e6590>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x13488dbd0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x1345ec820>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x1349da920>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x1345962f0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x1348869e0>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 35.75), tabular LP value : (-1.0, 35.75)  --  Reconstructed Max plane alpha: (-1.0, 35.75), reconstructed tabular alpha : (-1.0, 35.75)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13429c5e0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.4267053701015966, 21.167634252539912), tabular LP value : (-1.4267053701015966, 21.167634252539912)  --  Reconstructed Max plane alpha: (-1.4267053701015968, 21.167634252539912), reconstructed tabular alpha : (-1.4267053701015968, 21.167634252539912)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1348cd1e0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 22.625), tabular LP value : (-1.0, 22.625)  --  Reconstructed Max plane alpha: (-1.0, 22.625), reconstructed tabular alpha : (-1.0, 22.625)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x13475c3d0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 27.375), tabular LP value : (-1.0, 27.375)  --  Reconstructed Max plane alpha: (-1.0, 27.375), reconstructed tabular alpha : (-1.0, 27.375)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13465a4a0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.9869683008338468, 65.1051780847474), tabular LP value : (-1.9869683008338468, 65.1051780847474)  --  Reconstructed Max plane alpha: (-1.9869683008338468, 65.1051780847474), reconstructed tabular alpha : (-1.9869683008338468, 65.1051780847474)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134b9cd60>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 60\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13475c970>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134887be0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134906f80>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1345e5780>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x13475fc10>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.45 0.05 0.45]  -- DR <decisionRule.DecisionRule object at 0x134886d10>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x1349b6260>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x1346fdc00>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.05 0.05 0.45 0.45]  -- DR <decisionRule.DecisionRule object at 0x1347be290>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x134610040>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x1348cdf90>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x1346fe050>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x134597400>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x1346599c0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x134884220>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x1348cf8e0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 0.0), tabular LP value : (0.0, 0.0)  --  Reconstructed Max plane alpha: (0.0, 0.0), reconstructed tabular alpha : (0.0, 0.0)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x134ada920>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 35.75), tabular LP value : (-1.0, 35.75)  --  Reconstructed Max plane alpha: (-1.0, 35.75), reconstructed tabular alpha : (-1.0, 35.75)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1346fdc30>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.4267053701015966, 21.167634252539912), tabular LP value : (-1.4267053701015966, 21.167634252539912)  --  Reconstructed Max plane alpha: (-1.4267053701015968, 21.167634252539912), reconstructed tabular alpha : (-1.4267053701015968, 21.167634252539912)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1349b6f50>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 22.625), tabular LP value : (-1.0, 22.625)  --  Reconstructed Max plane alpha: (-1.0, 22.625), reconstructed tabular alpha : (-1.0, 22.625)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134885510>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 27.375), tabular LP value : (-1.0, 27.375)  --  Reconstructed Max plane alpha: (-1.0, 27.375), reconstructed tabular alpha : (-1.0, 27.375)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13465aad0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.9869683008338468, 65.1051780847474), tabular LP value : (-1.9869683008338468, 65.1051780847474)  --  Reconstructed Max plane alpha: (-1.9869683008338468, 65.1051780847474), reconstructed tabular alpha : (-1.9869683008338468, 65.1051780847474)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1347bc460>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (-1.9869683008338468, 65.1051780847474)\n",
      "alphavectors value at inital belief (V0,V1) : (-1.9869683008338468, 65.1051780847474)\n",
      "\n",
      "\n",
      "\n",
      "EXTRACTING STACKELBERG POLICIES ... \n",
      "\t\t\t Solving stackelberg relay4 GAME WITH SOTA True 1 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.71084337349398), tabular LP value : (0.0, 26.71084337349398)  --  Reconstructed Max plane alpha: (0.0, 26.71084337349398), reconstructed tabular alpha : (0.0, 26.71084337349398)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1346fd480>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.71084337349398), tabular LP value : (0.0, 26.71084337349398)  --  Reconstructed Max plane alpha: (0.0, 26.71084337349398), reconstructed tabular alpha : (0.0, 26.71084337349398)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13475de40>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 4\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.71084337349398), tabular LP value : (0.0, 26.71084337349398)  --  Reconstructed Max plane alpha: (0.0, 26.71084337349398), reconstructed tabular alpha : (0.0, 26.71084337349398)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134a360b0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (0.0, 26.71084337349398)\n",
      "alphavectors value at inital belief (V0,V1) : (0.0, 26.71084337349398)\n",
      "\n",
      "\n",
      "\t\t\t Solving stackelberg relay4 GAME WITH SOTA True 2 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 9\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.71084337349398), tabular LP value : (0.0, 26.71084337349398)  --  Reconstructed Max plane alpha: (0.0, 26.71084337349398), reconstructed tabular alpha : (0.0, 26.71084337349398)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13461d030>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.85542168674699), tabular LP value : (0.0, 26.85542168674699)  --  Reconstructed Max plane alpha: (0.0, 26.855421686746993), reconstructed tabular alpha : (0.0, 26.855421686746993)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134abd120>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 24.66265060240964), tabular LP value : (0.0, 24.66265060240964)  --  Reconstructed Max plane alpha: (0.0, 24.66265060240964), reconstructed tabular alpha : (0.0, 24.66265060240964)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1348cc460>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 32.12048192771085), tabular LP value : (0.0, 32.12048192771085)  --  Reconstructed Max plane alpha: (0.0, 32.12048192771085), reconstructed tabular alpha : (0.0, 32.12048192771085)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1347bd420>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 35.75), tabular LP value : (-1.0, 35.75)  --  Reconstructed Max plane alpha: (-1.0, 35.75), reconstructed tabular alpha : (-1.0, 35.75)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134884370>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 15\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.71084337349398), tabular LP value : (0.0, 26.71084337349398)  --  Reconstructed Max plane alpha: (0.0, 26.71084337349398), reconstructed tabular alpha : (0.0, 26.71084337349398)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13461a9b0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.85542168674699), tabular LP value : (0.0, 26.85542168674699)  --  Reconstructed Max plane alpha: (0.0, 26.855421686746993), reconstructed tabular alpha : (0.0, 26.855421686746993)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134aec7f0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 24.66265060240964), tabular LP value : (0.0, 24.66265060240964)  --  Reconstructed Max plane alpha: (0.0, 24.66265060240964), reconstructed tabular alpha : (0.0, 24.66265060240964)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134595120>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 32.12048192771085), tabular LP value : (0.0, 32.12048192771085)  --  Reconstructed Max plane alpha: (0.0, 32.12048192771085), reconstructed tabular alpha : (0.0, 32.12048192771085)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x13488e800>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 35.75), tabular LP value : (-1.0, 35.75)  --  Reconstructed Max plane alpha: (-1.0, 35.75), reconstructed tabular alpha : (-1.0, 35.75)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13498e350>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 17\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.71084337349398), tabular LP value : (0.0, 26.71084337349398)  --  Reconstructed Max plane alpha: (0.0, 26.71084337349398), reconstructed tabular alpha : (0.0, 26.71084337349398)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134887eb0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.85542168674699), tabular LP value : (0.0, 26.85542168674699)  --  Reconstructed Max plane alpha: (0.0, 26.855421686746993), reconstructed tabular alpha : (0.0, 26.855421686746993)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x1349b74c0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 24.66265060240964), tabular LP value : (0.0, 24.66265060240964)  --  Reconstructed Max plane alpha: (0.0, 24.66265060240964), reconstructed tabular alpha : (0.0, 24.66265060240964)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1345e40d0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 32.12048192771085), tabular LP value : (0.0, 32.12048192771085)  --  Reconstructed Max plane alpha: (0.0, 32.12048192771085), reconstructed tabular alpha : (0.0, 32.12048192771085)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1349688b0>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 35.75), tabular LP value : (-1.0, 35.75)  --  Reconstructed Max plane alpha: (-1.0, 35.75), reconstructed tabular alpha : (-1.0, 35.75)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1349b7fa0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (-1.0, 35.75)\n",
      "alphavectors value at inital belief (V0,V1) : (-1.0, 35.75)\n",
      "\n",
      "\n",
      "\t\t\t Solving stackelberg relay4 GAME WITH SOTA True 3 \n",
      "iteration : 1 , density = 0.25\n",
      "\tbelief expansion done, belief space size = 11\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.71084337349398), tabular LP value : (0.0, 26.71084337349398)  --  Reconstructed Max plane alpha: (0.0, 26.71084337349398), reconstructed tabular alpha : (0.0, 26.71084337349398)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1345e6860>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.85542168674699), tabular LP value : (0.0, 26.85542168674699)  --  Reconstructed Max plane alpha: (0.0, 26.855421686746993), reconstructed tabular alpha : (0.0, 26.855421686746993)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x13496c460>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 24.66265060240964), tabular LP value : (0.0, 24.66265060240964)  --  Reconstructed Max plane alpha: (0.0, 24.66265060240964), reconstructed tabular alpha : (0.0, 24.66265060240964)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1345e5360>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 32.12048192771085), tabular LP value : (0.0, 32.12048192771085)  --  Reconstructed Max plane alpha: (0.0, 32.12048192771085), reconstructed tabular alpha : (0.0, 32.12048192771085)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134aee470>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 28.609638554216872), tabular LP value : (0.0, 28.609638554216872)  --  Reconstructed Max plane alpha: (0.0, 28.609638554216875), reconstructed tabular alpha : (0.0, 28.609638554216875)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x1346ffee0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 22.643373493975908), tabular LP value : (0.0, 22.643373493975908)  --  Reconstructed Max plane alpha: (0.0, 22.643373493975908), reconstructed tabular alpha : (0.0, 22.643373493975908)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x134914730>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 22.3387951807229), tabular LP value : (0.0, 22.3387951807229)  --  Reconstructed Max plane alpha: (0.0, 22.338795180722897), reconstructed tabular alpha : (0.0, 22.338795180722897)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x13454a980>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 22.947951807228918), tabular LP value : (0.0, 22.947951807228918)  --  Reconstructed Max plane alpha: (0.0, 22.947951807228918), reconstructed tabular alpha : (0.0, 22.947951807228918)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x13470d5a0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 34.880481927710846), tabular LP value : (0.0, 34.880481927710846)  --  Reconstructed Max plane alpha: (0.0, 34.88048192771085), reconstructed tabular alpha : (0.0, 34.88048192771085)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x134b890f0>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 35.75), tabular LP value : (-1.0, 35.75)  --  Reconstructed Max plane alpha: (-1.0, 35.75), reconstructed tabular alpha : (-1.0, 35.75)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1348f7190>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.4267053701015966, 21.167634252539912), tabular LP value : (-1.4267053701015966, 21.167634252539912)  --  Reconstructed Max plane alpha: (-1.4267053701015968, 21.167634252539912), reconstructed tabular alpha : (-1.4267053701015968, 21.167634252539912)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134a07d00>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 22.625), tabular LP value : (-1.0, 22.625)  --  Reconstructed Max plane alpha: (-1.0, 22.625), reconstructed tabular alpha : (-1.0, 22.625)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x13475f190>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 27.375), tabular LP value : (-1.0, 27.375)  --  Reconstructed Max plane alpha: (-1.0, 27.375), reconstructed tabular alpha : (-1.0, 27.375)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1346fd000>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-2.0, 33.0), tabular LP value : (-2.0, 33.0)  --  Reconstructed Max plane alpha: (-2.0, 33.0), reconstructed tabular alpha : (-2.0, 33.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134abda80>\n",
      "\n",
      "iteration : 2 , density = 0.1255\n",
      "\tbelief expansion done, belief space size = 21\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.71084337349398), tabular LP value : (0.0, 26.71084337349398)  --  Reconstructed Max plane alpha: (0.0, 26.71084337349398), reconstructed tabular alpha : (0.0, 26.71084337349398)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13488f970>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.85542168674699), tabular LP value : (0.0, 26.85542168674699)  --  Reconstructed Max plane alpha: (0.0, 26.855421686746993), reconstructed tabular alpha : (0.0, 26.855421686746993)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134bb2170>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 24.66265060240964), tabular LP value : (0.0, 24.66265060240964)  --  Reconstructed Max plane alpha: (0.0, 24.66265060240964), reconstructed tabular alpha : (0.0, 24.66265060240964)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134ae0b80>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 32.12048192771085), tabular LP value : (0.0, 32.12048192771085)  --  Reconstructed Max plane alpha: (0.0, 32.12048192771085), reconstructed tabular alpha : (0.0, 32.12048192771085)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134a87730>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 28.609638554216872), tabular LP value : (0.0, 28.609638554216872)  --  Reconstructed Max plane alpha: (0.0, 28.609638554216875), reconstructed tabular alpha : (0.0, 28.609638554216875)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x13468d510>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 28.427710843373497), tabular LP value : (0.0, 28.427710843373497)  --  Reconstructed Max plane alpha: (0.0, 28.427710843373497), reconstructed tabular alpha : (0.0, 28.427710843373497)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x13465b190>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 22.643373493975908), tabular LP value : (0.0, 22.643373493975908)  --  Reconstructed Max plane alpha: (0.0, 22.643373493975908), reconstructed tabular alpha : (0.0, 22.643373493975908)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x13421b7f0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 22.3387951807229), tabular LP value : (0.0, 22.3387951807229)  --  Reconstructed Max plane alpha: (0.0, 22.338795180722897), reconstructed tabular alpha : (0.0, 22.338795180722897)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x13454f100>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 22.947951807228918), tabular LP value : (0.0, 22.947951807228918)  --  Reconstructed Max plane alpha: (0.0, 22.947951807228918), reconstructed tabular alpha : (0.0, 22.947951807228918)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x134857730>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 34.880481927710846), tabular LP value : (0.0, 34.880481927710846)  --  Reconstructed Max plane alpha: (0.0, 34.88048192771085), reconstructed tabular alpha : (0.0, 34.88048192771085)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x1346fd3f0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 27.254457831325304), tabular LP value : (0.0, 27.254457831325304)  --  Reconstructed Max plane alpha: (0.0, 27.254457831325308), reconstructed tabular alpha : (0.0, 27.254457831325308)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x1346279a0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 23.024096385542165), tabular LP value : (0.0, 23.024096385542165)  --  Reconstructed Max plane alpha: (0.0, 23.024096385542173), reconstructed tabular alpha : (0.0, 23.024096385542173)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x1348d6800>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.30120481927711), tabular LP value : (0.0, 26.30120481927711)  --  Reconstructed Max plane alpha: (0.0, 26.301204819277114), reconstructed tabular alpha : (0.0, 26.301204819277114)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x1345c3940>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 36.44819277108434), tabular LP value : (0.0, 36.44819277108434)  --  Reconstructed Max plane alpha: (0.0, 36.448192771084344), reconstructed tabular alpha : (0.0, 36.448192771084344)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x13421b400>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 27.79277108433735), tabular LP value : (0.0, 27.79277108433735)  --  Reconstructed Max plane alpha: (0.0, 27.792771084337353), reconstructed tabular alpha : (0.0, 27.792771084337353)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x134a87580>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 35.75), tabular LP value : (-1.0, 35.75)  --  Reconstructed Max plane alpha: (-1.0, 35.75), reconstructed tabular alpha : (-1.0, 35.75)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13454e980>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.4267053701015966, 21.167634252539912), tabular LP value : (-1.4267053701015966, 21.167634252539912)  --  Reconstructed Max plane alpha: (-1.4267053701015968, 21.167634252539912), reconstructed tabular alpha : (-1.4267053701015968, 21.167634252539912)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134917d60>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 22.625), tabular LP value : (-1.0, 22.625)  --  Reconstructed Max plane alpha: (-1.0, 22.625), reconstructed tabular alpha : (-1.0, 22.625)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1340b53f0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 27.375), tabular LP value : (-1.0, 27.375)  --  Reconstructed Max plane alpha: (-1.0, 27.375), reconstructed tabular alpha : (-1.0, 27.375)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134627220>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-2.0, 33.0), tabular LP value : (-2.0, 33.0)  --  Reconstructed Max plane alpha: (-2.0, 33.0), reconstructed tabular alpha : (-2.0, 33.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134745cc0>\n",
      "\n",
      "iteration : 3 , density = 0.001\n",
      "\tbelief expansion done, belief space size = 60\n",
      "\n",
      "========================= backup at timestep 2 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.71084337349398), tabular LP value : (0.0, 26.71084337349398)  --  Reconstructed Max plane alpha: (0.0, 26.71084337349398), reconstructed tabular alpha : (0.0, 26.71084337349398)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x13468cbe0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.85542168674699), tabular LP value : (0.0, 26.85542168674699)  --  Reconstructed Max plane alpha: (0.0, 26.855421686746993), reconstructed tabular alpha : (0.0, 26.855421686746993)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134854130>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 24.66265060240964), tabular LP value : (0.0, 24.66265060240964)  --  Reconstructed Max plane alpha: (0.0, 24.66265060240964), reconstructed tabular alpha : (0.0, 24.66265060240964)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x134a84250>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 32.12048192771085), tabular LP value : (0.0, 32.12048192771085)  --  Reconstructed Max plane alpha: (0.0, 32.12048192771085), reconstructed tabular alpha : (0.0, 32.12048192771085)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x134821c90>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 28.609638554216872), tabular LP value : (0.0, 28.609638554216872)  --  Reconstructed Max plane alpha: (0.0, 28.609638554216875), reconstructed tabular alpha : (0.0, 28.609638554216875)  --  belief [0.45 0.05 0.45 0.05]  -- DR <decisionRule.DecisionRule object at 0x1340b5210>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 25.101204819277108), tabular LP value : (0.0, 25.101204819277108)  --  Reconstructed Max plane alpha: (0.0, 25.10120481927711), reconstructed tabular alpha : (0.0, 25.10120481927711)  --  belief [0.05 0.45 0.05 0.45]  -- DR <decisionRule.DecisionRule object at 0x134856350>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 28.427710843373497), tabular LP value : (0.0, 28.427710843373497)  --  Reconstructed Max plane alpha: (0.0, 28.427710843373497), reconstructed tabular alpha : (0.0, 28.427710843373497)  --  belief [0.0625 0.3125 0.3125 0.3125]  -- DR <decisionRule.DecisionRule object at 0x134bb1780>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 22.643373493975908), tabular LP value : (0.0, 22.643373493975908)  --  Reconstructed Max plane alpha: (0.0, 22.643373493975908), reconstructed tabular alpha : (0.0, 22.643373493975908)  --  belief [0.45 0.45 0.05 0.05]  -- DR <decisionRule.DecisionRule object at 0x134a86680>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 31.06746987951807), tabular LP value : (0.0, 31.06746987951807)  --  Reconstructed Max plane alpha: (0.0, 31.06746987951808), reconstructed tabular alpha : (0.0, 31.06746987951808)  --  belief [0.05 0.05 0.45 0.45]  -- DR <decisionRule.DecisionRule object at 0x1348d4d90>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 22.3387951807229), tabular LP value : (0.0, 22.3387951807229)  --  Reconstructed Max plane alpha: (0.0, 22.338795180722897), reconstructed tabular alpha : (0.0, 22.338795180722897)  --  belief [0.81 0.09 0.09 0.01]  -- DR <decisionRule.DecisionRule object at 0x1346fcb20>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 22.947951807228918), tabular LP value : (0.0, 22.947951807228918)  --  Reconstructed Max plane alpha: (0.0, 22.947951807228918), reconstructed tabular alpha : (0.0, 22.947951807228918)  --  belief [0.09 0.81 0.01 0.09]  -- DR <decisionRule.DecisionRule object at 0x13454dbd0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 34.880481927710846), tabular LP value : (0.0, 34.880481927710846)  --  Reconstructed Max plane alpha: (0.0, 34.88048192771085), reconstructed tabular alpha : (0.0, 34.88048192771085)  --  belief [0.09 0.01 0.81 0.09]  -- DR <decisionRule.DecisionRule object at 0x134605e10>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 27.254457831325304), tabular LP value : (0.0, 27.254457831325304)  --  Reconstructed Max plane alpha: (0.0, 27.254457831325308), reconstructed tabular alpha : (0.0, 27.254457831325308)  --  belief [0.01 0.09 0.09 0.81]  -- DR <decisionRule.DecisionRule object at 0x1348207c0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 23.024096385542165), tabular LP value : (0.0, 23.024096385542165)  --  Reconstructed Max plane alpha: (0.0, 23.024096385542173), reconstructed tabular alpha : (0.0, 23.024096385542173)  --  belief [0.  0.9 0.  0.1]  -- DR <decisionRule.DecisionRule object at 0x1345a9e10>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 26.30120481927711), tabular LP value : (0.0, 26.30120481927711)  --  Reconstructed Max plane alpha: (0.0, 26.301204819277114), reconstructed tabular alpha : (0.0, 26.301204819277114)  --  belief [0.  0.1 0.  0.9]  -- DR <decisionRule.DecisionRule object at 0x1348d6c50>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 36.44819277108434), tabular LP value : (0.0, 36.44819277108434)  --  Reconstructed Max plane alpha: (0.0, 36.448192771084344), reconstructed tabular alpha : (0.0, 36.448192771084344)  --  belief [0.  0.  0.9 0.1]  -- DR <decisionRule.DecisionRule object at 0x134604b20>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (0.0, 27.79277108433735), tabular LP value : (0.0, 27.79277108433735)  --  Reconstructed Max plane alpha: (0.0, 27.792771084337353), reconstructed tabular alpha : (0.0, 27.792771084337353)  --  belief [0.  0.  0.1 0.9]  -- DR <decisionRule.DecisionRule object at 0x1340b4a00>\n",
      "\n",
      "========================= backup at timestep 1 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 35.75), tabular LP value : (-1.0, 35.75)  --  Reconstructed Max plane alpha: (-1.0, 35.75), reconstructed tabular alpha : (-1.0, 35.75)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x134856620>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.4267053701015966, 21.167634252539912), tabular LP value : (-1.4267053701015966, 21.167634252539912)  --  Reconstructed Max plane alpha: (-1.4267053701015968, 21.167634252539912), reconstructed tabular alpha : (-1.4267053701015968, 21.167634252539912)  --  belief [0.25 0.25 0.25 0.25]  -- DR <decisionRule.DecisionRule object at 0x134ae1fc0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 22.625), tabular LP value : (-1.0, 22.625)  --  Reconstructed Max plane alpha: (-1.0, 22.625), reconstructed tabular alpha : (-1.0, 22.625)  --  belief [0.  0.5 0.  0.5]  -- DR <decisionRule.DecisionRule object at 0x1346066b0>\n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-1.0, 27.375), tabular LP value : (-1.0, 27.375)  --  Reconstructed Max plane alpha: (-1.0, 27.375), reconstructed tabular alpha : (-1.0, 27.375)  --  belief [0.  0.  0.5 0.5]  -- DR <decisionRule.DecisionRule object at 0x1349e2110>\n",
      "\n",
      "========================= backup at timestep 0 =========================== \n",
      "\n",
      "Game stackelberg  ::  max plane LP value: (-2.0, 33.0), tabular LP value : (-2.0, 33.0)  --  Reconstructed Max plane alpha: (-2.0, 33.0), reconstructed tabular alpha : (-2.0, 33.0)  --  belief [0. 0. 0. 1.]  -- DR <decisionRule.DecisionRule object at 0x1346255d0>\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "=========================================================== END ======================================================================\n",
      "\n",
      "point value at initial belief  (-2.0, 33.0)\n",
      "alphavectors value at inital belief (V0,V1) : (-2.0, 33.0)\n",
      "\n",
      "\n",
      "\n",
      "EXTRACTING STACKELBERG POLICIES ... \n",
      "calculating stackelberg comparsion matrix...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gametype</th>\n",
       "      <th>SOTA</th>\n",
       "      <th>horizon</th>\n",
       "      <th>iterations</th>\n",
       "      <th>time</th>\n",
       "      <th>number_of_beliefs</th>\n",
       "      <th>values</th>\n",
       "      <th>tabular value</th>\n",
       "      <th>density</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cooperative</td>\n",
       "      <td>Stackelberg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.029877185821533203, 0.057389259338378906, 0...</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]</td>\n",
       "      <td>[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cooperative</td>\n",
       "      <td>Stackelberg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.16916799545288086, 0.30388784408569336, 0.4...</td>\n",
       "      <td>[9, 15, 17]</td>\n",
       "      <td>[(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]</td>\n",
       "      <td>[(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cooperative</td>\n",
       "      <td>Stackelberg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.4018678665161133, 1.001262903213501, 1.6853...</td>\n",
       "      <td>[11, 21, 60]</td>\n",
       "      <td>[(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]</td>\n",
       "      <td>[(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cooperative</td>\n",
       "      <td>State of the Art</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.0019910335540771484, 0.0037598609924316406,...</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]</td>\n",
       "      <td>[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cooperative</td>\n",
       "      <td>State of the Art</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.01026296615600586, 0.0206758975982666, 0.03...</td>\n",
       "      <td>[9, 15, 17]</td>\n",
       "      <td>[(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]</td>\n",
       "      <td>[(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cooperative</td>\n",
       "      <td>State of the Art</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.03398776054382324, 0.09691071510314941, 0.1...</td>\n",
       "      <td>[11, 21, 60]</td>\n",
       "      <td>[(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]</td>\n",
       "      <td>[(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>zerosum</td>\n",
       "      <td>Stackelberg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.029267072677612305, 0.05668210983276367, 0....</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]</td>\n",
       "      <td>[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>zerosum</td>\n",
       "      <td>Stackelberg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.14586901664733887, 0.31457090377807617, 0.4...</td>\n",
       "      <td>[9, 15, 17]</td>\n",
       "      <td>[(-50.0, 50.0), (-50.0, 50.0), (-50.0, 50.0)]</td>\n",
       "      <td>[(-50.0, 50.0), (-50.0, 50.0), (-50.0, 50.0)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>zerosum</td>\n",
       "      <td>Stackelberg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.46378183364868164, 1.1626038551330566, 1.90...</td>\n",
       "      <td>[11, 21, 60]</td>\n",
       "      <td>[(-50.85878962536023, 50.85878962536023), (-50...</td>\n",
       "      <td>[(-50.85878962536023, 50.85878962536023), (-50...</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>zerosum</td>\n",
       "      <td>State of the Art</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.04025888442993164, 0.08011698722839355, 0.1...</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]</td>\n",
       "      <td>[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>zerosum</td>\n",
       "      <td>State of the Art</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.20420408248901367, 0.4098958969116211, 0.62...</td>\n",
       "      <td>[9, 15, 17]</td>\n",
       "      <td>[(-50.0, 50.0), (-50.0, 50.0), (-50.0, 50.0)]</td>\n",
       "      <td>[(-50.0, 50.0), (-50.0, 50.0), (-50.0, 50.0)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>zerosum</td>\n",
       "      <td>State of the Art</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.5771291255950928, 1.4942679405212402, 2.498...</td>\n",
       "      <td>[11, 21, 60]</td>\n",
       "      <td>[(-50.0, 50.0), (-50.0, 50.0), (-50.0, 50.0)]</td>\n",
       "      <td>[(-50.85878962536023, 50.85878962536023), (-50...</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>stackelberg</td>\n",
       "      <td>Stackelberg</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.028048038482666016, 0.05615520477294922, 0....</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]</td>\n",
       "      <td>[(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>stackelberg</td>\n",
       "      <td>Stackelberg</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.14456510543823242, 0.28743720054626465, 0.4...</td>\n",
       "      <td>[9, 15, 17]</td>\n",
       "      <td>[(-1.0, 35.75), (-1.0, 35.75), (-1.0, 35.75)]</td>\n",
       "      <td>[(-1.0, 35.75), (-1.0, 35.75), (-1.0, 35.75)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>stackelberg</td>\n",
       "      <td>Stackelberg</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.46994996070861816, 1.1037721633911133, 1.80...</td>\n",
       "      <td>[11, 21, 60]</td>\n",
       "      <td>[(-1.9869683008338468, 65.1051780847474), (-1....</td>\n",
       "      <td>[(-1.9869683008338468, 65.1051780847474), (-1....</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>stackelberg</td>\n",
       "      <td>State of the Art</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.02974700927734375, 0.05986523628234863, 0.0...</td>\n",
       "      <td>[4, 4, 4]</td>\n",
       "      <td>[(0.0, 26.71084337349398), (0.0, 26.7108433734...</td>\n",
       "      <td>[(0.0, 26.71084337349398), (0.0, 26.7108433734...</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>stackelberg</td>\n",
       "      <td>State of the Art</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.15932083129882812, 0.344498872756958, 0.503...</td>\n",
       "      <td>[9, 15, 17]</td>\n",
       "      <td>[(-1.0, 35.75), (-1.0, 35.75), (-1.0, 35.75)]</td>\n",
       "      <td>[(-1.0, 35.75), (-1.0, 35.75), (-1.0, 35.75)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>stackelberg</td>\n",
       "      <td>State of the Art</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>[0.49748992919921875, 1.2162508964538574, 2.04...</td>\n",
       "      <td>[11, 21, 60]</td>\n",
       "      <td>[(-2.0, 33.0), (-2.0, 33.0), (-2.0, 33.0)]</td>\n",
       "      <td>[(-2.0, 33.0), (-2.0, 33.0), (-2.0, 33.0)]</td>\n",
       "      <td>[0.25, 0.1255, 0.001]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       gametype              SOTA  horizon  iterations  \\\n",
       "0   cooperative       Stackelberg        1           3   \n",
       "1   cooperative       Stackelberg        2           3   \n",
       "2   cooperative       Stackelberg        3           3   \n",
       "3   cooperative  State of the Art        1           3   \n",
       "4   cooperative  State of the Art        2           3   \n",
       "5   cooperative  State of the Art        3           3   \n",
       "6       zerosum       Stackelberg        1           3   \n",
       "7       zerosum       Stackelberg        2           3   \n",
       "8       zerosum       Stackelberg        3           3   \n",
       "9       zerosum  State of the Art        1           3   \n",
       "10      zerosum  State of the Art        2           3   \n",
       "11      zerosum  State of the Art        3           3   \n",
       "12  stackelberg       Stackelberg        1           3   \n",
       "13  stackelberg       Stackelberg        2           3   \n",
       "14  stackelberg       Stackelberg        3           3   \n",
       "15  stackelberg  State of the Art        1           3   \n",
       "16  stackelberg  State of the Art        2           3   \n",
       "17  stackelberg  State of the Art        3           3   \n",
       "\n",
       "                                                 time number_of_beliefs  \\\n",
       "0   [0.029877185821533203, 0.057389259338378906, 0...         [4, 4, 4]   \n",
       "1   [0.16916799545288086, 0.30388784408569336, 0.4...       [9, 15, 17]   \n",
       "2   [0.4018678665161133, 1.001262903213501, 1.6853...      [11, 21, 60]   \n",
       "3   [0.0019910335540771484, 0.0037598609924316406,...         [4, 4, 4]   \n",
       "4   [0.01026296615600586, 0.0206758975982666, 0.03...       [9, 15, 17]   \n",
       "5   [0.03398776054382324, 0.09691071510314941, 0.1...      [11, 21, 60]   \n",
       "6   [0.029267072677612305, 0.05668210983276367, 0....         [4, 4, 4]   \n",
       "7   [0.14586901664733887, 0.31457090377807617, 0.4...       [9, 15, 17]   \n",
       "8   [0.46378183364868164, 1.1626038551330566, 1.90...      [11, 21, 60]   \n",
       "9   [0.04025888442993164, 0.08011698722839355, 0.1...         [4, 4, 4]   \n",
       "10  [0.20420408248901367, 0.4098958969116211, 0.62...       [9, 15, 17]   \n",
       "11  [0.5771291255950928, 1.4942679405212402, 2.498...      [11, 21, 60]   \n",
       "12  [0.028048038482666016, 0.05615520477294922, 0....         [4, 4, 4]   \n",
       "13  [0.14456510543823242, 0.28743720054626465, 0.4...       [9, 15, 17]   \n",
       "14  [0.46994996070861816, 1.1037721633911133, 1.80...      [11, 21, 60]   \n",
       "15  [0.02974700927734375, 0.05986523628234863, 0.0...         [4, 4, 4]   \n",
       "16  [0.15932083129882812, 0.344498872756958, 0.503...       [9, 15, 17]   \n",
       "17  [0.49748992919921875, 1.2162508964538574, 2.04...      [11, 21, 60]   \n",
       "\n",
       "                                               values  \\\n",
       "0                [(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]   \n",
       "1          [(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]   \n",
       "2          [(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]   \n",
       "3                [(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]   \n",
       "4          [(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]   \n",
       "5          [(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]   \n",
       "6                [(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]   \n",
       "7       [(-50.0, 50.0), (-50.0, 50.0), (-50.0, 50.0)]   \n",
       "8   [(-50.85878962536023, 50.85878962536023), (-50...   \n",
       "9                [(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]   \n",
       "10      [(-50.0, 50.0), (-50.0, 50.0), (-50.0, 50.0)]   \n",
       "11      [(-50.0, 50.0), (-50.0, 50.0), (-50.0, 50.0)]   \n",
       "12               [(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]   \n",
       "13      [(-1.0, 35.75), (-1.0, 35.75), (-1.0, 35.75)]   \n",
       "14  [(-1.9869683008338468, 65.1051780847474), (-1....   \n",
       "15  [(0.0, 26.71084337349398), (0.0, 26.7108433734...   \n",
       "16      [(-1.0, 35.75), (-1.0, 35.75), (-1.0, 35.75)]   \n",
       "17         [(-2.0, 33.0), (-2.0, 33.0), (-2.0, 33.0)]   \n",
       "\n",
       "                                        tabular value                density  \n",
       "0                [(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]  [0.25, 0.1255, 0.001]  \n",
       "1          [(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]  [0.25, 0.1255, 0.001]  \n",
       "2          [(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]  [0.25, 0.1255, 0.001]  \n",
       "3                [(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]  [0.25, 0.1255, 0.001]  \n",
       "4          [(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]  [0.25, 0.1255, 0.001]  \n",
       "5          [(-1.0, -1.0), (-1.0, -1.0), (-1.0, -1.0)]  [0.25, 0.1255, 0.001]  \n",
       "6                [(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]  [0.25, 0.1255, 0.001]  \n",
       "7       [(-50.0, 50.0), (-50.0, 50.0), (-50.0, 50.0)]  [0.25, 0.1255, 0.001]  \n",
       "8   [(-50.85878962536023, 50.85878962536023), (-50...  [0.25, 0.1255, 0.001]  \n",
       "9                [(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]  [0.25, 0.1255, 0.001]  \n",
       "10      [(-50.0, 50.0), (-50.0, 50.0), (-50.0, 50.0)]  [0.25, 0.1255, 0.001]  \n",
       "11  [(-50.85878962536023, 50.85878962536023), (-50...  [0.25, 0.1255, 0.001]  \n",
       "12               [(0.0, 0.0), (0.0, 0.0), (0.0, 0.0)]  [0.25, 0.1255, 0.001]  \n",
       "13      [(-1.0, 35.75), (-1.0, 35.75), (-1.0, 35.75)]  [0.25, 0.1255, 0.001]  \n",
       "14  [(-1.9869683008338468, 65.1051780847474), (-1....  [0.25, 0.1255, 0.001]  \n",
       "15  [(0.0, 26.71084337349398), (0.0, 26.7108433734...  [0.25, 0.1255, 0.001]  \n",
       "16      [(-1.0, 35.75), (-1.0, 35.75), (-1.0, 35.75)]  [0.25, 0.1255, 0.001]  \n",
       "17         [(-2.0, 33.0), (-2.0, 33.0), (-2.0, 33.0)]  [0.25, 0.1255, 0.001]  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "database, matrix = experiment.run_experiments_decreasing_density(num_iterations,initial_density=0.001)\n",
    "pd.DataFrame(database)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/izzikampono/Documents/GitHub/Thesis/experimentFunctions.py:150: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data = self.database[self.database[\"gametype\"]==gametype][self.database[\"horizon\"]==self.planning_horizon]\n",
      "/Users/izzikampono/Documents/GitHub/Thesis/experimentFunctions.py:150: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data = self.database[self.database[\"gametype\"]==gametype][self.database[\"horizon\"]==self.planning_horizon]\n",
      "/Users/izzikampono/Documents/GitHub/Thesis/experimentFunctions.py:150: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data = self.database[self.database[\"gametype\"]==gametype][self.database[\"horizon\"]==self.planning_horizon]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/izzikampono/Documents/GitHub/Thesis/experimentFunctions.py:127: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data = self.database[self.database[\"gametype\"]==gametype][self.database[\"horizon\"]==horizon]\n",
      "/Users/izzikampono/Documents/GitHub/Thesis/experimentFunctions.py:127: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data = self.database[self.database[\"gametype\"]==gametype][self.database[\"horizon\"]==horizon]\n",
      "/Users/izzikampono/Documents/GitHub/Thesis/experimentFunctions.py:127: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data = self.database[self.database[\"gametype\"]==gametype][self.database[\"horizon\"]==horizon]\n",
      "/Users/izzikampono/Documents/GitHub/Thesis/experimentFunctions.py:127: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data = self.database[self.database[\"gametype\"]==gametype][self.database[\"horizon\"]==horizon]\n",
      "/Users/izzikampono/Documents/GitHub/Thesis/experimentFunctions.py:127: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data = self.database[self.database[\"gametype\"]==gametype][self.database[\"horizon\"]==horizon]\n",
      "/Users/izzikampono/Documents/GitHub/Thesis/experimentFunctions.py:127: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data = self.database[self.database[\"gametype\"]==gametype][self.database[\"horizon\"]==horizon]\n",
      "/Users/izzikampono/Documents/GitHub/Thesis/experimentFunctions.py:127: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data = self.database[self.database[\"gametype\"]==gametype][self.database[\"horizon\"]==horizon]\n",
      "/Users/izzikampono/Documents/GitHub/Thesis/experimentFunctions.py:127: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data = self.database[self.database[\"gametype\"]==gametype][self.database[\"horizon\"]==horizon]\n",
      "/Users/izzikampono/Documents/GitHub/Thesis/experimentFunctions.py:127: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  data = self.database[self.database[\"gametype\"]==gametype][self.database[\"horizon\"]==horizon]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "experiment.plots()\n",
    "experiment.horizon_value_plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.generate_summary_table()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
